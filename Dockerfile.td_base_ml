# Use a local container set up like this:
# https://github.com/TurbulentDynamics/TD-env-setup-dev-help/env-setup/nvidia-docker2-base-ml-container.md
#FROM local_td_base
FROM turbulentdynamics/td_base

# Install python modules
RUN pip install --upgrade pip
RUN pip install -U --user --trusted-host pypi.python.org pandas matplotlib dask pillow wheel setuptools mock 'future>=0.17.1'
RUN pip install -U --user jupyterlab


#Install Tensorflow from source to use all CPU instructions
RUN pip install -U --user keras_applications==1.0.6 --no-deps
RUN pip install -U --user keras_preprocessing==1.0.5 --no-deps


#Install bazel to build tensorflow https://docs.bazel.build/versions/master/install-ubuntu.html 
ARG BAZELVERSION=1.1.0
RUN wget https://github.com/bazelbuild/bazel/releases/download/$BAZELVERSION/bazel-$BAZELVERSION-installer-darwin-x86_64.sh
RUN chmod +x bazel-$BAZELVERSION-installer-linux-x86_64.sh
RUN ./bazel-$BAZELVERSION-installer-linux-x86_64.sh --user
RUN export PATH="$PATH:$HOME/bin"

RUN git clone https://github.com/tensorflow/tensorflow.git
RUN cd tensorflow
RUN ./configure cuda=Y





#Use these to install pre-compiled binaries, HOWEVER, these will not use all CPU instructions available
#RUN pip install tensorflow-gpu
#RUN pip install --user tensorflow==2.0.0-alpha0 
#RUN pip install --user tensorflow-gpu==2.0.0-alpha0 
#RUN pip install --user tf-nightly-gpu 
#RUN pip install --user keras
#RUN pip install https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp35-cp35m-linux_x86_64.whl
#RUN pip install --user torchvision


# Copy the current directory contents into the container at /app
#COPY . /app


# Make port 8888 available to the world outside this container
#EXPOSE 8888


# Run app.py when the container launches
# CMD ["jupyter", "lab"]

